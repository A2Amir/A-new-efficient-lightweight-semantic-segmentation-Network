{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import  Conv2D, Conv2DTranspose, UpSampling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import SpatialDropout2D, Permute, Activation, Reshape, PReLU\n",
    "from tensorflow.keras.layers import concatenate, add, Input\n",
    "from tensorflow.keras.layers import BatchNormalization, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['EENet']\n",
    "\n",
    "def initial_block(inp, number_filter = 13, filter_size = (3,3), stride = (2,2)):\n",
    "    \n",
    "    conv = Conv2D(number_filter, filter_size, padding = \"same\", strides = stride ) (inp) \n",
    "    max_pool = MaxPooling2D() (inp)\n",
    "    merged = concatenate ([conv,max_pool], axis = 3)\n",
    "    batch = BatchNormalization(momentum = 0.1)(merged)  # enet_unpooling uses momentum of 0.1, keras default is 0.99\n",
    "    output = PReLU(shared_axes = [1, 2])(batch)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottleneck(inp, number_filter = 32, internal_scale = 4, asymmetric = 0, dilated = 0, downsample = False, dropout_rate = 0.1):\n",
    "    \n",
    "    # main branch\n",
    "    internal = number_filter // internal_scale\n",
    "    encoder = inp\n",
    "    \n",
    "    # 1x1\n",
    "    input_stride = 2 if downsample else 1  # the 1st 1x1 projection is replaced with a 2x2 convolution when downsampling\n",
    "    encoder = Conv2D(internal,(input_stride, input_stride), (input_stride,input_stride) , use_bias =  False) (encoder)\n",
    "\n",
    "    # Batch normalization + PReLU\n",
    "    encoder = BatchNormalization(momentum = 0.1) (encoder)\n",
    "    encoder = PReLU(shared_axes=[1, 2])(encoder)\n",
    "    \n",
    "    #con\n",
    "    if not asymmetric and not dilated:\n",
    "        encoder =  Conv2D(internal, (3,3),padding = \"same\" ) (encoder)\n",
    "    elif asymmetric:\n",
    "        encoder = Conv2D(internal, (1, asymmetric), use_bias = False, padding = \"same\") (encoder)\n",
    "        encoder = Conv2D(internal, ( asymmetric, 1), padding = \"same\") (encoder)\n",
    "    elif dilated:\n",
    "        encoder = Conv2D(internal, (3,3), dilation_rate = (dilated, dilated), padding = \"same\") (encoder)\n",
    "    \n",
    "    # Batch normalization + PReLU\n",
    "    encoder = BatchNormalization(momentum = 0.1) (encoder)\n",
    "    encoder = PReLU(shared_axes=[1, 2])(encoder)\n",
    "   \n",
    "    # 1x1\n",
    "    encoder = Conv2D(number_filter, (1, 1), use_bias=False)(encoder)\n",
    "    encoder = BatchNormalization(momentum=0.1)(encoder)  # enet uses momentum of 0.1, keras default is 0.99\n",
    "    encoder = SpatialDropout2D(dropout_rate)(encoder)\n",
    "    \n",
    "    other = inp\n",
    "    if downsample:\n",
    "        other = MaxPooling2D()(other)\n",
    "\n",
    "        other = Permute((1, 3, 2))(other)\n",
    "\n",
    "        pad_feature_maps = number_filter - inp.get_shape().as_list()[3]\n",
    "        tb_pad = (0, 0)\n",
    "        lr_pad = (0, pad_feature_maps)\n",
    "        other = ZeroPadding2D(padding=(tb_pad, lr_pad))(other)\n",
    "        other = Permute((1, 3, 2))(other)\n",
    "    \n",
    "    encoder = add([encoder, other])\n",
    "    encoder = PReLU(shared_axes=[1, 2])(encoder)\n",
    "    \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.random.uniform((1,256,256,3),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = initial_block( img)   # #if  inpput = (1,256,256,3) output is TensorShape([1, 128, 128, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 128, 128, 16])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = bottleneck(img1, number_filter = 32, downsample = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 64, 64, 32])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = Permute((1, 3, 2))(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 128, 16, 128])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def en_build(inp, dropout_rate=0.01):\n",
    "    \n",
    "    en_input = initial_block(inp)\n",
    "    #print(en_input.shape)\n",
    "    \n",
    "    enc_layer1 = bottleneck(en_input, 32, downsample=True, dropout_rate=dropout_rate)  # bottleneck 1.0\n",
    "    for _ in range(4):\n",
    "        enc_layer1 = bottleneck(enc_layer1, 32, dropout_rate=dropout_rate)  # bottleneck 1.i\n",
    "    #print(enc_layer1.shape)\n",
    "    \n",
    "    enc_layer2 = bottleneck(enc_layer1, 64, downsample=True)  # bottleneck 2.0\n",
    "    # bottleneck 2.x and 3.x\n",
    "    for _ in range(2):\n",
    "        enc_layer2 = bottleneck(enc_layer2, 64)  # bottleneck 2.1\n",
    "        enc_layer2 = bottleneck(enc_layer2, 64, dilated=2)  # bottleneck 2.2\n",
    "        enc_layer2 = bottleneck(enc_layer2, 64, asymmetric=5)  # bottleneck 2.3\n",
    "        enc_layer2 = bottleneck(enc_layer2, 64, dilated=4)  # bottleneck 2.4\n",
    "        enc_layer2 = bottleneck(enc_layer2, 64)  # bottleneck 2.5\n",
    "        enc_layer2 = bottleneck(enc_layer2, 64, dilated=8)  # bottleneck 2.6\n",
    "        enc_layer2 = bottleneck(enc_layer2, 64, asymmetric=5)  # bottleneck 2.7\n",
    "        enc_layer2 = bottleneck(enc_layer2, 64, dilated=16)  # bottleneck 2.8\n",
    "    #print(enc_layer2.shape)\n",
    "    \n",
    "    enc_layer3 = bottleneck(enc_layer2, 128, downsample=True)  # bottleneck 2.0\n",
    "    # bottleneck 2.x and 3.x\n",
    "    for _ in range(2):\n",
    "        enc_layer3 = bottleneck(enc_layer3, 128)  # bottleneck 2.1\n",
    "        enc_layer3 = bottleneck(enc_layer3, 128, dilated=2)  # bottleneck 2.2\n",
    "        enc_layer3 = bottleneck(enc_layer3, 128, asymmetric=5)  # bottleneck 2.3\n",
    "        enc_layer3 = bottleneck(enc_layer3, 128, dilated=4)  # bottleneck 2.4\n",
    "        enc_layer3 = bottleneck(enc_layer3, 128)  # bottleneck 2.5\n",
    "        enc_layer3 = bottleneck(enc_layer3, 128, dilated=8)  # bottleneck 2.6\n",
    "        enc_layer3 = bottleneck(enc_layer3, 128, asymmetric=5)  # bottleneck 2.7\n",
    "        enc_layer3 = bottleneck(enc_layer3, 128, dilated=16)  # bottleneck 2.8\n",
    "    #print(enc_layer3.shape)\n",
    "    \n",
    "    \n",
    "    return en_input, enc_layer1, enc_layer2, enc_layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_input, enc_layer1, enc_layer2, enc_layer3 = en_build(img, dropout_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 128, 16) (1, 64, 64, 32) (1, 32, 32, 64) (1, 16, 16, 128)\n"
     ]
    }
   ],
   "source": [
    "print(en_input.shape, enc_layer1.shape, enc_layer2.shape, enc_layer3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_bottleneck(encoder,decoder, number_filter, upsample=False, reverse_module=False):\n",
    "    \n",
    "    if decoder is not None:\n",
    "        encoder = add([encoder, decoder])\n",
    "        \n",
    "    internal = number_filter // 4\n",
    "\n",
    "    x = Conv2D(internal, (1, 1), use_bias=False)(encoder)\n",
    "    x = BatchNormalization(momentum=0.1)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    if not upsample:\n",
    "        x = Conv2D(internal, (3, 3), padding='same', use_bias=True)(x)\n",
    "    else:\n",
    "        x = Conv2DTranspose(filters=internal, kernel_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization(momentum=0.1)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(number_filter, (1, 1), padding='same', use_bias=False)(x)\n",
    "\n",
    "    other = encoder\n",
    "    if encoder.get_shape()[-1] != number_filter or upsample:\n",
    "        other = Conv2D(number_filter, (1, 1), padding='same', use_bias=False)(other)\n",
    "        other = BatchNormalization(momentum=0.1)(other)\n",
    "        if upsample and reverse_module is not False:\n",
    "            other = UpSampling2D(size=(2, 2))(other)\n",
    "\n",
    "    if upsample and reverse_module is False:\n",
    "        decoder = x\n",
    "    else:\n",
    "        x = BatchNormalization(momentum=0.1)(x)\n",
    "        decoder = add([x, other])\n",
    "        decoder = Activation('relu')(decoder)\n",
    "\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_1 = de_bottleneck(enc_layer3,None, 64, upsample=True, reverse_module=True)\n",
    "dec_1 = de_bottleneck(dec_1,None, 64)  # bottleneck 4.1\n",
    "dec_1 = de_bottleneck(dec_1,None, 64)  # bottleneck 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 32, 32, 64])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_2 = de_bottleneck(dec_1,enc_layer2, 32, upsample=True, reverse_module=True)  # bottleneck 5.0\n",
    "dec_2 = de_bottleneck(dec_2,None, 32)  # bottleneck 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 64, 64, 32]), TensorShape([1, 64, 64, 32]))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_2.shape, enc_layer1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_3 = de_bottleneck(dec_2, enc_layer1, 32, upsample=True, reverse_module=True)  # bottleneck 5.0\n",
    "dec_3 = de_bottleneck(dec_3,None, 32)  # bottleneck 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
